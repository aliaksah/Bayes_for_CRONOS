---
title: "Analysis Plan for Kepler Data"
author: "Aliaksandr Hubin"
output:
  html_document:
    df_print: paged
---

```{r}
#devtools::install_github("https://github.com/jonlachmann/GMJMCMC/tree/FBMS")
library(FBMS) 
library(tidyverse) 
library(DataExplorer)
#setwd("Task_Kepler")
```

# Load the data and perform EDA

```{r}
data = read.csv("https://raw.githubusercontent.com/OpenExoplanetCatalogue/oec_tables/master/comma_separated/open_exoplanet_catalogue.txt")


head(data)
DataExplorer::plot_str(data = data)
DataExplorer::plot_intro(data = data) 
DataExplorer::plot_missing(data = data)
DataExplorer::plot_density(data[,-2],nrow = 2,ncol = 3)
DataExplorer::plot_density(log(data[,c("eccentricity","mass","period","semimajoraxis","hoststar_radius","hoststar_mass")]),nrow = 2,ncol = 3)
DataExplorer::plot_correlation(data[,-2],type = "continuous",cor_args = list(use = "pairwise.complete.obs", method = "pearson"))

```

# Select relevant columns for analysis

We shall keep 300 observations as a hold out test set and the rest as the training set

```{r}
data <- data %>% select(semimajoraxis,mass, radius, period, eccentricity, hoststar_mass, hoststar_radius, hoststar_metallicity,hoststar_temperature,binaryflag) %>% na.omit()
summary(data)

set.seed(1)
te.ind <- sample.int(n = 939,size = 300,replace = F)
data.train = data[-te.ind,]
data.test = data[te.ind,]
```

# Iteration 1: Simple Bayesian Gaussian regression model with model averaging and Jeffreys prior

```{r}
set.seed(1)
blr <- FBMS::fbms(semimajoraxis ~ ., data = data.train, N = 5000)
plot(blr)
summary(blr,labels = names(data.train)[-1],effects = c(0.025,0.975),tol = 0)

```

Check stability

```{r}
set.seed(1)
all.probs <- sapply(1:20,FUN = function(x)FBMS::fbms(semimajoraxis ~ ., data = data.train, transforms = NULL, N = 5000)$marg.probs)

chain_means <- rowMeans(all.probs)
chain_sd <- sapply(1:9, function(i) sd(all.probs[i,]))

alpha_upper <- chain_means + 1.96*chain_sd
alpha_lower <- chain_means - 1.96*chain_sd

stability <- data.frame(covariate = names(data)[-1],one.chain = round(blr$marg.probs[1,],4),mean = round(chain_means,4),lower = round(alpha_lower,4),upper = round(alpha_upper,4))

print(stability)
```

### Marginal Inclusion Probabilities

The marginal inclusion probabilities indicate the likelihood that each predictor is included in the model. High probabilities suggest that the predictor is likely important for explaining the response variable.

1.  **period** is included in the model with absolute certainty. The orbital period is a fundamental characteristic of an orbit and strongly influences the semimajor axis due to Kepler's third law, which relates the square of the period to the cube of the semimajor axis.

2.  **mass** is also almost certainly included in the model. The mass of the orbiting body can affect the dynamics of the system, influencing the semimajor axis through gravitational interactions.

3.  **eccentricity** has a high inclusion probability. The eccentricity of an orbit describes its deviation from a perfect circle, which can affect the semimajor axis as it alters the orbital shape.

4.  ...

5.  **hoststar_mass** has a posterior inclusion below 0.0001 that would indicate it is not important, which is a bit counter-intuitive.

### Quantiles of Effect Sizes

The quantiles of model averaged effect sizes of posterior modes across all models provide the 2.5% and 97.5% quantiles for the posterior distribution of each coefficient. We shall look at the predictors with marginal inclusion probabilities above 0.5

1.  **mass**: The positive interval indicates that as the mass increases, the semimajor axis is expected to increase. This makes sense physically, as a larger mass could imply a more substantial gravitational influence, potentially affecting the orbit's size.

2.  **period**: The very narrow interval indicates a precise positive effect of the orbital period on the semimajor axis, consistent with Kepler's third law.

3.  **eccentricity**: The wide interval, spanning from zero to a significant positive value, indicates uncertainty about the effect of eccentricity, but it can have a large positive effect.

    But let us additionally look at the 95% CrI for the median probability model, which under Jeffreys priors approximately correspond to the 95% CI, allowing us to easily obtain the estimates using the lm function in R

    ```{r}
    summary(lm(semimajoraxis ~ 1 + mass + period + eccentricity, data = data.train))
    ```

essentially supporting the conclusions of model averaged posterior modes with the only exception of that now for the median probability model the 95% CrI does not include 0 for eccentricity. Let us now test predictive ability of the model and then discuss if we are satisfied with it.

### Make predictions

```{r}
preds.train <- predict(blr, data.train[,-1])
preds.test <- predict(blr, data.test[,-1])
r.blr <- round(c(cor(data.train[,1],preds.train$mean)^2,cor(data.test[,1],preds.test$mean)^2),3)
plot(x = data.train[, 1], preds.train$mean, xlab = "data", ylab = "prediction", main = "Title of the Plot", col = "blue", pch = 16)
points(x = data.test[, 1], preds.test$mean, col = "red", pch = 17)
legend("topright", legend = c(paste0("Training Data, R.sqr = ",r.blr[1]), paste0("Test Data, R.sqr = ",r.blr[2])), col = c("blue", "red"), pch = c(16, 17))
```

The predictions show extremely good predictive ability of the model for both training and testing data. Yet, let us reflect on potential pitfalls of the model do decide if we are interested in it.

### Possible criticism

The finding that the host star's mass is not important in predicting the semimajor axis does seem counterintuitive, as the mass of the host star should, in theory, have a significant influence on the orbit of the planets around it. Here are some potential reasons and considerations to critically evaluate this finding and whether it motivates the use of a more complex model:

1.  **Data Quality and Completeness**:

    -   **Missing or Inaccurate Data?** Yet we assumed missing at random for all missing data. But if there are inaccuracies or biases in missing data for host star mass, might it explain why this predictor is not showing importance? We believe it is not important even if we were missing the systems with high or low solar mass systematically as the solar mass would still be much higher than the mass of a planet. The only way it could be important is if the solar mass was constant or having close to zero variance. Yet as we saw in EDA, this is not the case.

2.  **Confounding Variables**:

    -   **Collinearity**: If host star mass is correlated with other predictors (e.g., period or eccentricity), its unique contribution might be overshadowed, leading to an underestimation of its importance. Again, this is not the case according to EDA.

3.  **Model Simplicity**:

    -   **Linear Model Limitations**: A simple linear model might not capture the complex relationships between host star mass and the semimajor axis, particularly if the relationship is non-linear or interacts with other variables. We could try more complex models. Multiplicative effects for the original model could be testes by a model with log transformed responses, while additive non-linearities through fractional polynomials. Finally, more complicated non-linear relationships with both non-linearities and interactions can be tested by a symbolic regression on BGNLM. Let us dig into this.

# Iteration 2: Bayesian Gaussian regression model with model averaging and Jeffreys and prior log-transformed response

Inference

```{r}
set.seed(1)
blr.log <- FBMS::fbms(log(semimajoraxis) ~ ., data = data.train, N = 5000)
plot(blr.log)
summary(blr.log,labels = names(data.train)[-1],effects = c(0.025,0.975))
```

#### 1. **Inclusion Probabilities:**

-   **High Inclusion Probabilities:** Period and eccentricity have perfect inclusion probabilities, indicating they are crucial predictors for the log-transformed semimajor axis.

-   **Strong Predictors:** Mass, radius, and hoststar_mass also show high inclusion probabilities

#### 2. **Effect Sizes:**

-   **Period:** The very narrow quantiles for period suggest a strong, consistent effect.

-   **Eccentricity:** The suggest that eccentricity has a significant positive effect on the log-transformed semimajor axis.

-   **Mass and Hoststar Mass:** Both mass and hoststar_mass show positive effects, with hoststar_mass being notably important, which aligns more closely with astrophysical expectations compared to the non-transformed model.

-   **Radius:** The interval for radius is wide, indicating more uncertainty in its effect.

-   **Other Predictors:** Hoststar_radius, hoststar_metallicity, and hoststar_temperature have wide intervals, suggesting they are less consistent predictors.

    let us also fit the median probability model here

    ```{r}
    summary(lm(log(semimajoraxis) ~ 1 + mass + period + eccentricity + radius + hoststar_mass, data = data.train))
    ```

corroborating the model averaged conclusions except for the radius which in MPM has a negative effect, however this makes sense as radius and mass are somewhat correlated and in the models with radius but without mass one would expect a positive effect of the former, hence the uncertainty in the posterior modes.

The log transformation of the response variable appears to improve the model in several ways:

-   **Increased Relevance of Predictors:** Variables such as hoststar_mass, which are theoretically important, now have significant inclusion probabilities and effect sizes.

-   **Better Fit to Physical Laws:** The transformed model better aligns with astrophysical principles, making the results more interpretable and reliable.

    But let us check the predictive quality of the model.

### Predictions

```{r}
preds.train.log <- predict(blr.log, data.train[,-1],link = exp)
preds.test.log <- predict(blr.log, data.test[,-1],link = exp)
r.blr.log <- round(c(cor(data.train[,1],preds.train.log$mean)^2,cor(data.test[,1],preds.test.log$mean)^2),3)
print(r.blr.log)
plot(x = data.train[, 1], preds.train.log$mean,ylim = c(min(preds.train$mean),max(preds.train$mean)), xlab = "data", ylab = "prediction", main = "Title of the Plot", col = "blue", pch = 16)
points(x = data.test[, 1], preds.test.log$mean, col = "red", pch = 17)
legend("topright", legend = c(paste0("Training Data, R.sqr = ",r.blr.log[1]), paste0("Test Data, R.sqr = ",r.blr.log[2])), col = c("blue", "red"), pch = c(16, 17))
```

While the log transformation resulted in more interpretatible physically model, it introduced challenges when interpreting predictions on the original scale. The lower predictive quality on the original scale highlights the need for careful consideration of transformation impacts and possibly more sophisticated modeling approaches to improve accuracy. Let us hence dig into Bayesian fractional polynomials.

# Iteration 3: More complex functional forms with Bayesian methods

Bayesian fractional polynomials

```{r}
transforms <- c("p0","p2","p3","p05","pm05","pm1","pm2","p0p0","p0p05","p0p1","p0p2","p0p3","p0p05","p0pm05","p0pm1","p0pm2")
probs <- gen.probs.gmjmcmc(transforms)
probs$gen <- c(0,1,0,1) # Only modifications!
params <- gen.params.gmjmcmc(data.train)
params$feat$D <- 1   # Set depth of features to 1
set.seed(1)
bfp <- FBMS::fbms(semimajoraxis ~ ., data = data.train,transforms = transforms,runs = 20,cores = 8,P = 20, probs = probs, params = params)
plot(bfp)
summary(bfp,labels = names(data.train)[-1])
```

Check convergence

```{r}
diagn_plot(bfp,window = 10,FUN = median)
diagn_plot(bfp,window = 10,FUN = max)
```

We see convergence after 17th generation of GMJMCMC, so let us further increase the number of populations and chains.

```{r}
set.seed(1)
bfp <- FBMS::fbms(semimajoraxis ~ ., data = data.train,transforms = transforms,probs = probs, params = params,runs = 64,cores = 8,P = 40)
plot(bfp)
summary(bfp,labels = names(data.train)[-1],effects = c(0.025,0.975))
```

we see the same important effects as in a shorter run. Let us check convergence

```{r}
diagn_plot(bfp,window = 10,FUN = median)
diagn_plot(bfp,window = 10,FUN = max)
```

Convergence seems rather stable for this class of models on this data set and with these tuning parameters of the sampler.

#### 1. **Importance of Period**:

-   The predictor `period` has an extremely high inclusion probability, indicating it is almost certainly a key predictor for the semimajor axis.

-   Fractional polynomial transformations of `period`, specifically `p0p05(period)` also show notable inclusion probability. This suggests that non-linear transformations of `period`are important for capturing the relationship with the semimajor axis.

#### 2. **Other Predictors**:

Predictors such as `mass`, `radius`, `hoststar_mass`, `hoststar_metallicity`, `hoststar_temperature`, `hoststar_radius`, and `eccentricity` have very low inclusion probabilities, all less than 0.001. This indicates that these variables are not significant predictors in the presence of the `period` and its transformations.

But let us look at MPM here as the model, just like for the model averaged effect, we see positive effect of period and its polynomial term, which makes sense.

```{r}
summary(lm(semimajoraxis ~ 1 + period + p0p05(period), data = data.train))
```

### Predictions

```{r}
preds.train.bfp <- predict(bfp, data.train[,-1])
preds.test.bfp <- predict(bfp, data.test[,-1])
r.bfp <- round(c(cor(data.train[,1],preds.train.bfp$aggr$mean)^2,cor(data.test[,1],preds.test.bfp$aggr$mean)^2),3)
plot(x = data.train[, 1], preds.train.bfp$aggr$mean, xlab = "data", ylab = "prediction", main = "Title of the Plot", col = "blue", pch = 16)
points(x = data.test[, 1], preds.test.bfp$aggr$mean, col = "red", pch = 17)
legend("topright", legend = c(paste0("Training Data, R.sqr = ",r.bfp[1]), paste0("Test Data, R.sqr = ",r.bfp[2])), col = c("blue", "red"), pch = c(16, 17))
```

The predictions are excellent and even slightly better than for the linear model. Yet, the low inclusion probabilities for predictors such as `hoststar_mass` suggest that these factors do not significantly improve the model once the period is accounted for. This might be due to the fact that the period encapsulates much of the necessary information about the orbit's size and shape. However, it's somewhat surprising that `hoststar_mass` has such a low inclusion probability, as it physically is expected to influence the orbital dynamics. This could indicate that the effect of host star mass is indirectly captured through the period, or it may be due to the specific data set and transformations used.

The limitation of a BFP model is the lack of interactions. So let us try out Bayesian generalized nonlinear models that allow to both model non-linearity and interactions.

### Bayesian generalized nonlinear models

```{r}
transforms <- c("sin_deg","exp_dbl","p0","troot","p3")
probs <- gen.probs.gmjmcmc(transforms)
params <- gen.params.gmjmcmc(data.train)
set.seed(1)
bgnlm <- FBMS::fbms(semimajoraxis ~ ., data = data.train,transforms = transforms,runs = 20,cores = 8,P = 20, probs = probs, params = params)
plot(bgnlm)
summary(bgnlm,labels = names(data.train)[-1])
```

check convergence

```{r}
diagn_plot(bgnlm,window = 10,FUN = median)
diagn_plot(bgnlm,window = 10,FUN = max)
```

we see possible convergence for the later generations of GMJMCMC, but let us increase the compute to check if it is indeed so. The limitation of the convergence statistics is that it may show perfect convergence upon algorithm stuck in a good mode and not mixing futher across the modes.

```{r}
set.seed(1)
bgnlm <- FBMS::fbms(semimajoraxis ~ ., data = data.train,transforms = transforms,runs = 64,cores = 8,P = 40,probs = probs, params = params)
plot(bgnlm)
summary(bgnlm,labels = names(data.train)[-1])
```

```{r}
diagn_plot(bgnlm,window = 10,FUN = median)
diagn_plot(bgnlm,window = 10,FUN = max)
```

```{r}
preds.train.bgnlm <- predict(bgnlm, data.train[,-1])
preds.test.bgnlm <- predict(bgnlm, data.test[,-1])
r.bgnlm <- round(c(cor(data.train[,1],preds.train.bgnlm$aggr$mean)^2,cor(data.test[,1],preds.test.bgnlm$aggr$mean)^2),3)
plot(x = data.train[, 1], preds.train.bgnlm$aggr$mean, xlab = "data", ylab = "prediction", main = "Title of the Plot", col = "blue", pch = 16)
points(x = data.test[, 1], preds.test.bgnlm$aggr$mean, col = "red", pch = 17)
legend("topright", legend = c(paste0("Training Data, R.sqr = ",r.bgnlm[1]), paste0("Test Data, R.sqr = ",r.bgnlm[2])), col = c("blue", "red"), pch = c(16, 17))
```

Very good predictions here. But to do a minimal check of reproducibility, let us first rerun the algorithm on the same data

```{r}
set.seed(2)
bgnlm <- FBMS::fbms(semimajoraxis ~ ., data = data.train,transforms = transforms,runs = 64,cores = 8,P = 40,probs = probs, params = params)
plot(bgnlm)
summary(bgnlm,labels = names(data.train)[-1])
```

Convergence

```{r}
diagn_plot(bgnlm,window = 10,FUN = median)
diagn_plot(bgnlm,window = 10,FUN = max)
```

We also see good convergence, yet with better log marginal posterior of the best models, meaning that previous run was stuck in a local extremum. \
\
In the Bayesian Generalized Nonlinear Model (BGNLM) analysis, you obtained the following results:

**Predictor: `troot(((period*hoststar_mass)*period))`** **Inclusion Probability: 1.000000**

This result indicates a perfect inclusion probability (1.0) for the predictor `troot(((period*hoststar_mass)*period))`, suggesting that this complex non-linear interaction term is crucial for predicting the semimajor axis.

### Interpretation

#### 1. **Complex Interaction Term**:

-   The predictor `troot(((period*hoststar_mass)*period))` combines `period` and `hoststar_mass` in a multiplicative form, followed by a transformation.

-   `troot` likely represents a specific non-linear transformation, such as a root function, which means the predictor is a transformed version of the product of `period`, `hoststar_mass`, and `period` again.

### Discussion with Relation to Kepler's Third Law

#### 1. **Kepler's Third Law**

Kepler's Third Law states that the square of the orbital period of a planet is proportional to the cube of the semimajor axis of its orbit.

#### 2. **Implications and Interpretation**

-   **Alignment with Physical Laws**: The inclusion of `troot(((period*hoststar_mass)*period))` in the BGNLM model supports Kepler’s Third Law by explicitly incorporating the cubic root transformation of the complicated interaction. This suggests that the model correctly captures the underlying (known in this case as Kepler's Third Law) physical relationship between the orbital period and the semimajor axis.

-   **Predictive Power and Physical Meaning**: The perfect inclusion probability of this term indicates that the model effectively leverages the cubic root relationship to predict the semimajor axis. This reinforces the physical validity of the model and emphasizes the importance of incorporating both the period and the host star’s mass in a non-linear fashion.

#### 2. **Comparison with Previous Models**:

-   **Linear and Log-Transformed Models**: These simpler models highlighted the importance of `period` and `hoststar_mass` individually, but the BGNLM model shows that their interaction, particularly in a non-linear form, is even more crucial.

-   **Fractional Polynomials**: The fractional polynomial model also indicated non-linear relationships but did not capture this specific interaction and it also missed the solar mass in its functional form, highlighting the added value of BGNLM in uncovering complex dependencies.

### Predictions

```{r}
preds.train.bgnlm <- predict(bgnlm, data.train[,-1])
preds.test.bgnlm <- predict(bgnlm, data.test[,-1])
r.bgnlm <- round(c(cor(data.train[,1],preds.train.bgnlm$aggr$mean)^2,cor(data.test[,1],preds.test.bgnlm$aggr$mean)^2),3)
plot(x = data.train[, 1], preds.train.bgnlm$aggr$mean, xlab = "data", ylab = "prediction", main = "Title of the Plot", col = "blue", pch = 16)
points(x = data.test[, 1], preds.test.bgnlm$aggr$mean, col = "red", pch = 17)
legend("topright", legend = c(paste0("Training Data, R.sqr = ",r.bgnlm[1]), paste0("Test Data, R.sqr = ",r.bgnlm[2])), col = c("blue", "red"), pch = c(16, 17))
```

The predictions are expectidely perfect on both training and testing sets, as inclusion of `troot(((period*hoststar_mass)*period))` in the BGNLM model effectively captures the essence of Kepler’s Third Law, incorporating the orbital period and the host star’s mass in a cubic root transformation. This predictor reflects the key physical relationship between these variables, demonstrating that the model is not only statistically sound but also physically meaningful. The high inclusion probability underscores the importance of this non-linear interaction in accurately predicting the semimajor axis.

And use the whole data and redo the inference.

```{r}
transforms <- c("sin_deg","exp_dbl","p0","troot","p3")
probs <- gen.probs.gmjmcmc(transforms)
params <- gen.params.gmjmcmc(data)
set.seed(1)
bgnlm <- FBMS::fbms(semimajoraxis ~ ., data = data,transforms = transforms,runs = 64,cores = 8,P = 40,probs = probs, params = params)
plot(bgnlm)
summary(bgnlm,labels = names(data.train)[-1])

```

Here we perfectly recover the true law!

We see that variation is possible in the results and that ideally maximal possible compute resources should be used to reduce the variation. But given enough resources GMJMCMC converges to being able to recover the true underlying physical law. It also seems that existing convergence tools may not be enough as they might be misleading in the situations of getting stuck in a good mode.
